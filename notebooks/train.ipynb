{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup (only on collab)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "!git clone https://github.com/alicebarbosam/fraud-detection-kaggle.git\n",
    "%cd fraud-detection-kaggle"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Setup"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import HistGradientBoostingClassifier\n",
    "import optuna\n",
    "import joblib\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dataset shape: (227845, 32)\n",
      "       id      Time        V1        V2        V3        V4        V5  \\\n",
      "0  265519  161919.0  1.946747 -0.752526 -1.355130 -0.661630  1.502822   \n",
      "1  180306  124477.0  2.035149 -0.048880 -3.058693  0.247945  2.943487   \n",
      "2   42665   41191.0 -0.991920  0.603193  0.711976 -0.992425 -0.825838   \n",
      "3  198724  132624.0  2.285718 -1.500239 -0.747565 -1.668119 -1.394143   \n",
      "4   82326   59359.0 -0.448747 -1.011440  0.115903 -3.454854  0.715771   \n",
      "\n",
      "         V6        V7        V8  ...       V21       V22       V23       V24  \\\n",
      "0  4.024933 -1.479661  1.139880  ...  0.076197  0.297537  0.307915  0.690980   \n",
      "1  3.298697 -0.002192  0.674782  ...  0.038628  0.228197  0.035542  0.707090   \n",
      "2  1.956261 -2.212603 -5.037523  ... -2.798352  0.109526 -0.436530 -0.932803   \n",
      "3 -0.350339 -1.427984  0.010010  ... -0.139670  0.077013  0.208310 -0.538236   \n",
      "4 -0.147490  0.504347 -0.113817  ... -0.243245 -0.173298 -0.006692 -1.362383   \n",
      "\n",
      "        V25       V26       V27       V28  Amount  Class  \n",
      "0 -0.350316 -0.388907  0.077641 -0.032248    7.32      0  \n",
      "1  0.512885 -0.471198  0.002520 -0.069002    2.99      0  \n",
      "2  0.826684  0.913773  0.038049  0.185340  175.10      0  \n",
      "3 -0.278032 -0.162068  0.018045 -0.063005    6.10      0  \n",
      "4 -0.292234 -0.144622 -0.032580 -0.064194   86.10      0  \n",
      "\n",
      "[5 rows x 32 columns]\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "print(\"Dataset shape:\", df.shape)\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pre processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X shape: (227845, 30)\n",
      "y shape: (227845,)\n",
      "Fraud rate (overall): 0.001729245759178389\n"
     ]
    }
   ],
   "source": [
    "target = \"Class\"\n",
    "\n",
    "X = df.drop(columns=[\"id\", target])\n",
    "y = df[target]\n",
    "\n",
    "print(\"X shape:\", X.shape)\n",
    "print(\"y shape:\", y.shape)\n",
    "print(\"Fraud rate (overall):\", y.mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train size: (182276, 30) | Fraud rate: 0.0017281485220215498\n",
      "Val size: (45569, 30) | Fraud rate: 0.0017336347078057452\n"
     ]
    }
   ],
   "source": [
    "#split treino e val\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X,\n",
    "    y,\n",
    "    test_size=0.2,\n",
    "    random_state=42,\n",
    "    stratify=y\n",
    ")\n",
    "\n",
    "print(\"Train size:\", X_train.shape, \"| Fraud rate:\", y_train.mean())\n",
    "print(\"Val size:\", X_val.shape, \"| Fraud rate:\", y_val.mean())\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = []\n",
    "\n",
    "def evaluate_model(model, X_val, y_val, model_name=\"Model\"):\n",
    "\n",
    "    val_probs = model.predict_proba(X_val)[:, 1]\n",
    "    roc_auc = roc_auc_score(y_val, val_probs)\n",
    "\n",
    "    print(f\"{model_name} ROC-AUC: {roc_auc:.4f}\")\n",
    "\n",
    "    results.append({\n",
    "        \"model\": model_name,\n",
    "        \"roc_auc\": roc_auc\n",
    "    })\n",
    "\n",
    "    return roc_auc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 1(Baseline) - Logistic Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Logistic Regression (scaled baseline) ROC-AUC: 0.9736\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.973616401991257"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "baseline_model = Pipeline([\n",
    "    (\"scaler\", StandardScaler()),  \n",
    "    (\"lr\", LogisticRegression(\n",
    "        max_iter=5000,              \n",
    "        class_weight=\"balanced\"\n",
    "    ))\n",
    "])\n",
    "\n",
    "baseline_model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(\n",
    "    baseline_model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    \"Logistic Regression (scaled baseline)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 2 - Random forest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Random Forest ROC-AUC: 0.9689\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9689318281107825"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    n_estimators=800,\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    class_weight=\"balanced_subsample\",\n",
    "    max_features=\"sqrt\",\n",
    "    max_depth=18,\n",
    "    min_samples_split=10,\n",
    "    min_samples_leaf=5\n",
    ")\n",
    "\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(\n",
    "    rf_model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    \"Random Forest\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 3 - HistGradientBoosting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "HistGradientBoosting (stronger) ROC-AUC: 0.9826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9825879105437"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\n",
    "\n",
    "hgb_model = HistGradientBoostingClassifier(\n",
    "    loss=\"log_loss\",\n",
    "    max_iter=600,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=6,\n",
    "    l2_regularization=0.1,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "hgb_model.fit(X_train, y_train)\n",
    "\n",
    "evaluate_model(\n",
    "    hgb_model,\n",
    "    X_val,\n",
    "    y_val,\n",
    "    \"HistGradientBoosting (stronger)\"\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 4 - XGBOOST\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.96276\n",
      "[200]\tvalidation_0-auc:0.96910\n",
      "[400]\tvalidation_0-auc:0.97430\n",
      "[600]\tvalidation_0-auc:0.97459\n",
      "[800]\tvalidation_0-auc:0.97515\n",
      "[1000]\tvalidation_0-auc:0.97452\n",
      "[1200]\tvalidation_0-auc:0.97426\n",
      "[1400]\tvalidation_0-auc:0.97392\n",
      "[1600]\tvalidation_0-auc:0.97470\n",
      "[1800]\tvalidation_0-auc:0.97504\n",
      "[2000]\tvalidation_0-auc:0.97539\n",
      "[2200]\tvalidation_0-auc:0.97576\n",
      "[2400]\tvalidation_0-auc:0.97580\n",
      "[2600]\tvalidation_0-auc:0.97603\n",
      "[2800]\tvalidation_0-auc:0.97586\n",
      "[3000]\tvalidation_0-auc:0.97589\n",
      "[3200]\tvalidation_0-auc:0.97600\n",
      "[3400]\tvalidation_0-auc:0.97607\n",
      "[3600]\tvalidation_0-auc:0.97595\n",
      "[3800]\tvalidation_0-auc:0.97623\n",
      "[4000]\tvalidation_0-auc:0.97604\n",
      "[4200]\tvalidation_0-auc:0.97649\n",
      "[4400]\tvalidation_0-auc:0.97642\n",
      "[4600]\tvalidation_0-auc:0.97643\n",
      "[4800]\tvalidation_0-auc:0.97646\n",
      "[5000]\tvalidation_0-auc:0.97649\n",
      "[5200]\tvalidation_0-auc:0.97647\n",
      "[5400]\tvalidation_0-auc:0.97666\n",
      "[5600]\tvalidation_0-auc:0.97684\n",
      "[5800]\tvalidation_0-auc:0.97692\n",
      "[6000]\tvalidation_0-auc:0.97696\n",
      "[6200]\tvalidation_0-auc:0.97698\n",
      "[6400]\tvalidation_0-auc:0.97694\n",
      "[6600]\tvalidation_0-auc:0.97696\n",
      "[6800]\tvalidation_0-auc:0.97698\n",
      "[7000]\tvalidation_0-auc:0.97697\n",
      "[7200]\tvalidation_0-auc:0.97708\n",
      "[7400]\tvalidation_0-auc:0.97713\n",
      "[7600]\tvalidation_0-auc:0.97719\n",
      "[7800]\tvalidation_0-auc:0.97719\n",
      "[8000]\tvalidation_0-auc:0.97728\n",
      "[8200]\tvalidation_0-auc:0.97738\n",
      "[8400]\tvalidation_0-auc:0.97730\n",
      "[8600]\tvalidation_0-auc:0.97730\n",
      "[8800]\tvalidation_0-auc:0.97740\n",
      "[9000]\tvalidation_0-auc:0.97733\n",
      "[9200]\tvalidation_0-auc:0.97733\n",
      "[9400]\tvalidation_0-auc:0.97734\n",
      "[9600]\tvalidation_0-auc:0.97730\n",
      "[9800]\tvalidation_0-auc:0.97735\n",
      "[10000]\tvalidation_0-auc:0.97741\n",
      "[10200]\tvalidation_0-auc:0.97742\n",
      "[10400]\tvalidation_0-auc:0.97743\n",
      "[10600]\tvalidation_0-auc:0.97739\n",
      "[10800]\tvalidation_0-auc:0.97734\n",
      "[11000]\tvalidation_0-auc:0.97733\n",
      "[11200]\tvalidation_0-auc:0.97742\n",
      "[11400]\tvalidation_0-auc:0.97739\n",
      "[11600]\tvalidation_0-auc:0.97742\n",
      "[11800]\tvalidation_0-auc:0.97743\n",
      "[12000]\tvalidation_0-auc:0.97737\n",
      "[12200]\tvalidation_0-auc:0.97730\n",
      "[12400]\tvalidation_0-auc:0.97733\n",
      "[12600]\tvalidation_0-auc:0.97735\n",
      "[12800]\tvalidation_0-auc:0.97736\n",
      "[13000]\tvalidation_0-auc:0.97736\n",
      "[13200]\tvalidation_0-auc:0.97739\n",
      "[13400]\tvalidation_0-auc:0.97740\n",
      "[13600]\tvalidation_0-auc:0.97742\n",
      "[13800]\tvalidation_0-auc:0.97743\n",
      "[14000]\tvalidation_0-auc:0.97743\n",
      "[14200]\tvalidation_0-auc:0.97746\n",
      "[14400]\tvalidation_0-auc:0.97742\n",
      "[14600]\tvalidation_0-auc:0.97741\n",
      "[14800]\tvalidation_0-auc:0.97740\n",
      "[14999]\tvalidation_0-auc:0.97739\n",
      "XGBoost (baseline) ROC-AUC: 0.9774\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "0.9773860439490109"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neg = (y_train == 0).sum()\n",
    "pos = (y_train == 1).sum()\n",
    "spw = neg / pos\n",
    "\n",
    "xgb_model = XGBClassifier(\n",
    "    n_estimators=15000,\n",
    "    learning_rate=0.02,\n",
    "    max_depth=7,\n",
    "    min_child_weight=6,\n",
    "    subsample=0.85,\n",
    "    colsample_bytree=0.85,\n",
    "    reg_lambda=5.0,\n",
    "    reg_alpha=0.1,\n",
    "    gamma=0.1,\n",
    "    scale_pos_weight=spw,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    tree_method=\"hist\",\n",
    ")\n",
    "\n",
    "xgb_model.fit(\n",
    "    X_train, y_train,\n",
    "    eval_set=[(X_val, y_val)],\n",
    "    verbose=200,\n",
    ")\n",
    "\n",
    "evaluate_model(xgb_model, X_val, y_val, \"XGBoost (baseline)\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 5 - HGB + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ROC-AUC: 0.988676\n",
      "Fold 2 ROC-AUC: 0.972383\n",
      "Fold 3 ROC-AUC: 0.972632\n",
      "Fold 4 ROC-AUC: 0.991376\n",
      "Fold 5 ROC-AUC: 0.981617\n",
      "\n",
      "HGB CV ROC-AUC Mean: 0.9813369333403081\n",
      "HGB CV ROC-AUC Std: 0.007882309892227303\n",
      "HGB CV ROC-AUC Mean ± Std: 0.981337 ± 0.007882\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), start=1):\n",
    "    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = HistGradientBoostingClassifier(\n",
    "        loss=\"log_loss\",\n",
    "        max_iter=600,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=6,\n",
    "        l2_regularization=0.1,\n",
    "        random_state=42\n",
    "    )\n",
    "\n",
    "    model.fit(X_train_cv, y_train_cv)\n",
    "\n",
    "    val_probs = model.predict_proba(X_val_cv)[:, 1]\n",
    "    fold_auc = roc_auc_score(y_val_cv, val_probs)\n",
    "\n",
    "    auc_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold} ROC-AUC: {fold_auc:.6f}\")\n",
    "\n",
    "auc_scores = np.array(auc_scores)\n",
    "\n",
    "print(\"\\nHGB CV ROC-AUC Mean:\", auc_scores.mean())\n",
    "print(\"HGB CV ROC-AUC Std:\", auc_scores.std())\n",
    "print(\"HGB CV ROC-AUC Mean ± Std:\", f\"{auc_scores.mean():.6f} ± {auc_scores.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 5 - XGBOOST + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fold 1 ROC-AUC: 0.996268\n",
      "Fold 2 ROC-AUC: 0.974153\n",
      "Fold 3 ROC-AUC: 0.976748\n",
      "Fold 4 ROC-AUC: 0.994501\n",
      "Fold 5 ROC-AUC: 0.981157\n",
      "\n",
      "XGB CV ROC-AUC Mean: 0.9845654497882943\n",
      "XGB CV ROC-AUC Std: 0.009130043051260611\n",
      "XGB CV ROC-AUC Mean ± Std: 0.984565 ± 0.009130\n"
     ]
    }
   ],
   "source": [
    "neg = (y == 0).sum()\n",
    "pos = (y == 1).sum()\n",
    "spw = neg / pos\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "auc_scores = []\n",
    "\n",
    "for fold, (train_idx, val_idx) in enumerate(cv.split(X, y), start=1):\n",
    "    X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "    y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "    model = XGBClassifier(\n",
    "        n_estimators=12000,\n",
    "        learning_rate=0.02,\n",
    "        max_depth=5,\n",
    "        min_child_weight=12,\n",
    "        subsample=0.8,\n",
    "        colsample_bytree=0.8,\n",
    "        reg_lambda=8.0,\n",
    "        reg_alpha=0.0,\n",
    "        gamma=0.0,\n",
    "        scale_pos_weight=spw,\n",
    "        objective=\"binary:logistic\",\n",
    "        eval_metric=\"auc\",\n",
    "        tree_method=\"hist\",\n",
    "        random_state=42,\n",
    "        n_jobs=-1\n",
    "    )\n",
    "\n",
    "    model.fit(\n",
    "        X_train_cv,\n",
    "        y_train_cv,\n",
    "        eval_set=[(X_val_cv, y_val_cv)],\n",
    "        verbose=False\n",
    "    )\n",
    "\n",
    "    val_probs = model.predict_proba(X_val_cv)[:, 1]\n",
    "    fold_auc = roc_auc_score(y_val_cv, val_probs)\n",
    "\n",
    "    auc_scores.append(fold_auc)\n",
    "    print(f\"Fold {fold} ROC-AUC: {fold_auc:.6f}\")\n",
    "\n",
    "auc_scores = np.array(auc_scores)\n",
    "\n",
    "print(\"\\nXGB CV ROC-AUC Mean:\", auc_scores.mean())\n",
    "print(\"XGB CV ROC-AUC Std:\", auc_scores.std())\n",
    "print(\"XGB CV ROC-AUC Mean ± Std:\", f\"{auc_scores.mean():.6f} ± {auc_scores.std():.6f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# MODEL 6 - XGBOOST + OPTUNA + CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/abm6/Desktop/projetos/fraud-detection-kaggle/.venv/lib/python3.13/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "\u001b[32m[I 2026-02-19 21:18:01,931]\u001b[0m A new study created in memory with name: no-name-e7dbbf0b-56bd-448b-bf41-640ae1a87f48\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:20:20,886]\u001b[0m Trial 0 finished with value: 0.9853409575673048 and parameters: {'n_estimators': 11319, 'learning_rate': 0.01322261614156472, 'max_depth': 7, 'min_child_weight': 4, 'subsample': 0.688702659006749, 'colsample_bytree': 0.6544210435172934, 'reg_lambda': 10.852913273335565, 'reg_alpha': 8.887608537441101e-05, 'gamma': 1.1544099949410547}. Best is trial 0 with value: 0.9853409575673048.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:23:07,920]\u001b[0m Trial 1 finished with value: 0.9860570129997018 and parameters: {'n_estimators': 13280, 'learning_rate': 0.013816785849589374, 'max_depth': 3, 'min_child_weight': 25, 'subsample': 0.6522782310926768, 'colsample_bytree': 0.8131612980375881, 'reg_lambda': 0.6641018004482382, 'reg_alpha': 1.5510669018303205e-05, 'gamma': 1.8210486606905327}. Best is trial 1 with value: 0.9860570129997018.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:24:29,812]\u001b[0m Trial 2 finished with value: 0.9816541860392836 and parameters: {'n_estimators': 7567, 'learning_rate': 0.015246389833748365, 'max_depth': 5, 'min_child_weight': 19, 'subsample': 0.9772070659016575, 'colsample_bytree': 0.8061280702744107, 'reg_lambda': 7.11379100004747, 'reg_alpha': 0.005962966422918651, 'gamma': 1.2679093840976647}. Best is trial 1 with value: 0.9860570129997018.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:26:05,549]\u001b[0m Trial 3 finished with value: 0.9866791462583722 and parameters: {'n_estimators': 9899, 'learning_rate': 0.019010010944903715, 'max_depth': 8, 'min_child_weight': 15, 'subsample': 0.8839782228552122, 'colsample_bytree': 0.7555801425199694, 'reg_lambda': 0.9842157889968307, 'reg_alpha': 0.016302863860982144, 'gamma': 1.9051245944394888}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:28:45,883]\u001b[0m Trial 4 finished with value: 0.9847008313768321 and parameters: {'n_estimators': 12149, 'learning_rate': 0.011119465195209873, 'max_depth': 6, 'min_child_weight': 1, 'subsample': 0.6382214947665553, 'colsample_bytree': 0.9617253153246642, 'reg_lambda': 3.8527459415902685, 'reg_alpha': 1.8854697671724237e-07, 'gamma': 0.2785490758053397}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:31:03,928]\u001b[0m Trial 5 finished with value: 0.9846351787043787 and parameters: {'n_estimators': 13049, 'learning_rate': 0.013011999678750935, 'max_depth': 4, 'min_child_weight': 20, 'subsample': 0.9291330594007139, 'colsample_bytree': 0.680429908650129, 'reg_lambda': 14.214811263404416, 'reg_alpha': 0.26528115214946757, 'gamma': 0.8290147806348585}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:32:07,028]\u001b[0m Trial 6 finished with value: 0.9864802470030272 and parameters: {'n_estimators': 5349, 'learning_rate': 0.039827323903536584, 'max_depth': 7, 'min_child_weight': 23, 'subsample': 0.7738538484952185, 'colsample_bytree': 0.9136469131329666, 'reg_lambda': 8.179980362556666, 'reg_alpha': 0.1338433017812272, 'gamma': 0.9842807609392734}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:34:00,617]\u001b[0m Trial 7 finished with value: 0.98464492927843 and parameters: {'n_estimators': 11230, 'learning_rate': 0.018622169677357837, 'max_depth': 4, 'min_child_weight': 10, 'subsample': 0.7485004483907403, 'colsample_bytree': 0.8293330383539357, 'reg_lambda': 0.05921762894516199, 'reg_alpha': 0.0048070313073756065, 'gamma': 1.2325722059937847}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:36:33,871]\u001b[0m Trial 8 finished with value: 0.9844611828281877 and parameters: {'n_estimators': 17165, 'learning_rate': 0.021451440203753586, 'max_depth': 3, 'min_child_weight': 10, 'subsample': 0.8368075102467285, 'colsample_bytree': 0.6548627805075661, 'reg_lambda': 0.14898236253140415, 'reg_alpha': 0.00343892324252374, 'gamma': 1.4434245952630134}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:37:26,794]\u001b[0m Trial 9 finished with value: 0.9850776057232606 and parameters: {'n_estimators': 5551, 'learning_rate': 0.03401788873268345, 'max_depth': 8, 'min_child_weight': 11, 'subsample': 0.8840142954073557, 'colsample_bytree': 0.7452996071329238, 'reg_lambda': 1.5280880920245863, 'reg_alpha': 3.8709952177945436e-05, 'gamma': 1.4466044925649835}. Best is trial 3 with value: 0.9866791462583722.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:40:05,245]\u001b[0m Trial 10 finished with value: 0.9878598479759676 and parameters: {'n_estimators': 19826, 'learning_rate': 0.05824100222662799, 'max_depth': 8, 'min_child_weight': 30, 'subsample': 0.8398169238893254, 'colsample_bytree': 0.7223500265798428, 'reg_lambda': 0.024088410548845373, 'reg_alpha': 1.8874265437127736e-08, 'gamma': 1.9897986004825168}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:42:39,440]\u001b[0m Trial 11 finished with value: 0.9875389998082376 and parameters: {'n_estimators': 19601, 'learning_rate': 0.05971831368100873, 'max_depth': 8, 'min_child_weight': 30, 'subsample': 0.8536634874023997, 'colsample_bytree': 0.736756611005288, 'reg_lambda': 0.023388408724719215, 'reg_alpha': 1.0775902051311743e-07, 'gamma': 1.9940366102105704}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:45:21,900]\u001b[0m Trial 12 finished with value: 0.9867306051384517 and parameters: {'n_estimators': 19959, 'learning_rate': 0.05761505251995946, 'max_depth': 7, 'min_child_weight': 30, 'subsample': 0.830652128939732, 'colsample_bytree': 0.7215554615061595, 'reg_lambda': 0.010823170055472597, 'reg_alpha': 1.3721132791813837e-08, 'gamma': 1.9578803309120603}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:48:01,294]\u001b[0m Trial 13 finished with value: 0.9857088715436522 and parameters: {'n_estimators': 19121, 'learning_rate': 0.059837220391772326, 'max_depth': 8, 'min_child_weight': 30, 'subsample': 0.7459031708010718, 'colsample_bytree': 0.6085293082592587, 'reg_lambda': 0.016085446772136844, 'reg_alpha': 8.723247732157148e-07, 'gamma': 1.674075511464347}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:50:22,975]\u001b[0m Trial 14 finished with value: 0.9852997176686408 and parameters: {'n_estimators': 15488, 'learning_rate': 0.042486050931176966, 'max_depth': 7, 'min_child_weight': 26, 'subsample': 0.8753941775345262, 'colsample_bytree': 0.8688838635049743, 'reg_lambda': 0.04740254841950659, 'reg_alpha': 1.9558318076342773e-08, 'gamma': 0.4393040596273743}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:52:32,685]\u001b[0m Trial 15 finished with value: 0.9819796633268034 and parameters: {'n_estimators': 17898, 'learning_rate': 0.030463707268851604, 'max_depth': 6, 'min_child_weight': 27, 'subsample': 0.9894710355004139, 'colsample_bytree': 0.7104390665262114, 'reg_lambda': 0.20788827587197328, 'reg_alpha': 9.988606016540441e-07, 'gamma': 1.6006350225520651}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:55:04,061]\u001b[0m Trial 16 finished with value: 0.9851587899099054 and parameters: {'n_estimators': 15591, 'learning_rate': 0.04750093978946275, 'max_depth': 8, 'min_child_weight': 22, 'subsample': 0.7956427077794265, 'colsample_bytree': 0.7724527767220881, 'reg_lambda': 0.0306278248864173, 'reg_alpha': 1.912345329795581e-07, 'gamma': 0.5927859328984622}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 21:57:39,087]\u001b[0m Trial 17 finished with value: 0.9859289930331407 and parameters: {'n_estimators': 15894, 'learning_rate': 0.027965518861423046, 'max_depth': 6, 'min_child_weight': 16, 'subsample': 0.7102840103618404, 'colsample_bytree': 0.8774319354065556, 'reg_lambda': 0.13281163508871366, 'reg_alpha': 5.581932839691288e-06, 'gamma': 1.6752666673505345}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:00:44,925]\u001b[0m Trial 18 finished with value: 0.9838968934161165 and parameters: {'n_estimators': 17911, 'learning_rate': 0.049842985455090534, 'max_depth': 5, 'min_child_weight': 28, 'subsample': 0.9354909490834189, 'colsample_bytree': 0.6091905332502348, 'reg_lambda': 0.3288287660927666, 'reg_alpha': 7.090040750282708e-08, 'gamma': 0.09603414088587903}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:03:32,927]\u001b[0m Trial 19 finished with value: 0.9866762412552499 and parameters: {'n_estimators': 19766, 'learning_rate': 0.037317513344434734, 'max_depth': 8, 'min_child_weight': 23, 'subsample': 0.8231176599811556, 'colsample_bytree': 0.6940198121779176, 'reg_lambda': 0.024420491662902985, 'reg_alpha': 0.00036507278405177097, 'gamma': 1.824840153662061}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:05:29,446]\u001b[0m Trial 20 finished with value: 0.9860533475987807 and parameters: {'n_estimators': 14413, 'learning_rate': 0.04880488604241583, 'max_depth': 7, 'min_child_weight': 30, 'subsample': 0.9176339198827868, 'colsample_bytree': 0.7767611952612803, 'reg_lambda': 0.09009127754278452, 'reg_alpha': 2.2117253967873757e-06, 'gamma': 1.9675347589832979}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:08:03,646]\u001b[0m Trial 21 finished with value: 0.9871895535383282 and parameters: {'n_estimators': 19854, 'learning_rate': 0.058689832753252395, 'max_depth': 7, 'min_child_weight': 30, 'subsample': 0.8398627782191433, 'colsample_bytree': 0.7256558426146986, 'reg_lambda': 0.010912399745338664, 'reg_alpha': 1.5179734774026164e-08, 'gamma': 1.99046028565345}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:10:35,167]\u001b[0m Trial 22 finished with value: 0.9863558274127792 and parameters: {'n_estimators': 18336, 'learning_rate': 0.05415354691866795, 'max_depth': 8, 'min_child_weight': 27, 'subsample': 0.8472033957055004, 'colsample_bytree': 0.7398656233416326, 'reg_lambda': 0.01168423294712846, 'reg_alpha': 4.601004879147087e-08, 'gamma': 1.513555681543692}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:13:02,602]\u001b[0m Trial 23 finished with value: 0.986927789830537 and parameters: {'n_estimators': 16873, 'learning_rate': 0.044510270930783004, 'max_depth': 7, 'min_child_weight': 25, 'subsample': 0.7972660796220387, 'colsample_bytree': 0.6607379842180328, 'reg_lambda': 0.027181628965194847, 'reg_alpha': 1.1100365698822342e-08, 'gamma': 1.7292890937553138}. Best is trial 10 with value: 0.9878598479759676.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:15:27,574]\u001b[0m Trial 24 finished with value: 0.9881910767195821 and parameters: {'n_estimators': 18460, 'learning_rate': 0.059630773223374595, 'max_depth': 8, 'min_child_weight': 30, 'subsample': 0.8638973220871323, 'colsample_bytree': 0.704838002168074, 'reg_lambda': 0.053813329656442845, 'reg_alpha': 2.737776706334933e-07, 'gamma': 1.9564355338957067}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:18:04,855]\u001b[0m Trial 25 finished with value: 0.9867874903928513 and parameters: {'n_estimators': 18759, 'learning_rate': 0.033852502046722396, 'max_depth': 8, 'min_child_weight': 28, 'subsample': 0.872091296915971, 'colsample_bytree': 0.6873042821573876, 'reg_lambda': 0.04892089361179436, 'reg_alpha': 3.715645509127811e-07, 'gamma': 1.7619559018179318}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:20:12,533]\u001b[0m Trial 26 finished with value: 0.9854353424104915 and parameters: {'n_estimators': 16874, 'learning_rate': 0.05124870460294405, 'max_depth': 8, 'min_child_weight': 20, 'subsample': 0.961644151438239, 'colsample_bytree': 0.7880009899986954, 'reg_lambda': 0.08188051802746855, 'reg_alpha': 7.483687344531084e-08, 'gamma': 1.4030314093783907}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:22:56,876]\u001b[0m Trial 27 finished with value: 0.9857730491871648 and parameters: {'n_estimators': 18714, 'learning_rate': 0.024778379320243092, 'max_depth': 6, 'min_child_weight': 24, 'subsample': 0.8995379334581962, 'colsample_bytree': 0.8453506336898113, 'reg_lambda': 0.023324106368693327, 'reg_alpha': 4.143597403515582e-06, 'gamma': 1.5801093924064082}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:25:11,347]\u001b[0m Trial 28 finished with value: 0.9863254499306755 and parameters: {'n_estimators': 14570, 'learning_rate': 0.0414756986369264, 'max_depth': 8, 'min_child_weight': 28, 'subsample': 0.861270879561138, 'colsample_bytree': 0.6323816795657231, 'reg_lambda': 0.3020125345788485, 'reg_alpha': 0.00037887026809976543, 'gamma': 1.8346691985953956}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n",
      "\u001b[32m[I 2026-02-19 22:27:38,082]\u001b[0m Trial 29 finished with value: 0.9852451552062386 and parameters: {'n_estimators': 17358, 'learning_rate': 0.05348921285680069, 'max_depth': 7, 'min_child_weight': 17, 'subsample': 0.8069887099754988, 'colsample_bytree': 0.7035151445174683, 'reg_lambda': 0.032267909479028974, 'reg_alpha': 5.375510676564954e-07, 'gamma': 1.1107756755103284}. Best is trial 24 with value: 0.9881910767195821.\u001b[0m\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Best CV ROC-AUC: 0.9881910767195821\n",
      "Best params:\n",
      "  n_estimators: 18460\n",
      "  learning_rate: 0.059630773223374595\n",
      "  max_depth: 8\n",
      "  min_child_weight: 30\n",
      "  subsample: 0.8638973220871323\n",
      "  colsample_bytree: 0.704838002168074\n",
      "  reg_lambda: 0.053813329656442845\n",
      "  reg_alpha: 2.737776706334933e-07\n",
      "  gamma: 1.9564355338957067\n"
     ]
    }
   ],
   "source": [
    "\n",
    "\n",
    "X = df.drop(columns=[\"id\", \"Class\"])\n",
    "y = df[\"Class\"]\n",
    "\n",
    "neg = (y == 0).sum()\n",
    "pos = (y == 1).sum()\n",
    "spw = neg / pos\n",
    "\n",
    "cv = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
    "\n",
    "def objective(trial):\n",
    "    params = {\n",
    "        \"n_estimators\": trial.suggest_int(\"n_estimators\", 5000, 20000),\n",
    "        \"learning_rate\": trial.suggest_float(\"learning_rate\", 0.01, 0.06, log=True),\n",
    "        \"max_depth\": trial.suggest_int(\"max_depth\", 3, 8),\n",
    "        \"min_child_weight\": trial.suggest_int(\"min_child_weight\", 1, 30),\n",
    "        \"subsample\": trial.suggest_float(\"subsample\", 0.6, 1.0),\n",
    "        \"colsample_bytree\": trial.suggest_float(\"colsample_bytree\", 0.6, 1.0),\n",
    "        \"reg_lambda\": trial.suggest_float(\"reg_lambda\", 1e-2, 20.0, log=True),\n",
    "        \"reg_alpha\": trial.suggest_float(\"reg_alpha\", 1e-8, 1.0, log=True),\n",
    "        \"gamma\": trial.suggest_float(\"gamma\", 0.0, 2.0),\n",
    "    }\n",
    "\n",
    "    fold_aucs = []\n",
    "\n",
    "    for train_idx, val_idx in cv.split(X, y):\n",
    "        X_train_cv, X_val_cv = X.iloc[train_idx], X.iloc[val_idx]\n",
    "        y_train_cv, y_val_cv = y.iloc[train_idx], y.iloc[val_idx]\n",
    "\n",
    "        model = XGBClassifier(\n",
    "            **params,\n",
    "            scale_pos_weight=spw,\n",
    "            objective=\"binary:logistic\",\n",
    "            eval_metric=\"auc\",\n",
    "            tree_method=\"hist\",\n",
    "            random_state=42,\n",
    "            n_jobs=-1\n",
    "        )\n",
    "\n",
    "        model.fit(X_train_cv, y_train_cv, verbose=False)\n",
    "\n",
    "        val_probs = model.predict_proba(X_val_cv)[:, 1]\n",
    "        fold_auc = roc_auc_score(y_val_cv, val_probs)\n",
    "        fold_aucs.append(fold_auc)\n",
    "\n",
    "    return float(np.mean(fold_aucs))\n",
    "\n",
    "\n",
    "study = optuna.create_study(direction=\"maximize\")\n",
    "study.optimize(objective, n_trials=30)\n",
    "\n",
    "print(\"\\nBest CV ROC-AUC:\", study.best_value)\n",
    "print(\"Best params:\")\n",
    "for k, v in study.best_params.items():\n",
    "    print(f\"  {k}: {v}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# FINAL MODEL - (XGB + CV + OPTUNA) \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0]\tvalidation_0-auc:0.83480\n",
      "[200]\tvalidation_0-auc:0.97139\n",
      "[400]\tvalidation_0-auc:0.97059\n",
      "[600]\tvalidation_0-auc:0.96906\n",
      "[800]\tvalidation_0-auc:0.97002\n",
      "[983]\tvalidation_0-auc:0.97105\n",
      "Saved model artifacts:\n",
      " - ../models/xgb_optuna_final.joblib\n",
      " - ../models/xgb_optuna_final.json\n"
     ]
    }
   ],
   "source": [
    "# usando todos os dadosa de treino\n",
    "train_df = pd.read_csv(\"../data/train.csv\")\n",
    "\n",
    "X_train_full = train_df.drop(columns=[\"id\", \"Class\"])\n",
    "y_train_full = train_df[\"Class\"]\n",
    "\n",
    "# scale_pos_weight do treino completo\n",
    "neg = (y_train_full == 0).sum()\n",
    "pos = (y_train_full == 1).sum()\n",
    "spw = neg / pos\n",
    "\n",
    "# melhores parametros descobertos por optuna\n",
    "best_params = {\n",
    "    \"n_estimators\": 25000,\n",
    "    \"learning_rate\": 0.03,\n",
    "    \"max_depth\": 8,\n",
    "    \"min_child_weight\": 30,\n",
    "    \"subsample\": 0.8638973220871323,\n",
    "    \"colsample_bytree\": 0.704838002168074,\n",
    "    \"reg_lambda\": 0.053813329656442845,\n",
    "    \"reg_alpha\": 2.737776706334933e-07,\n",
    "    \"gamma\": 1.9564355338957067,\n",
    "}\n",
    "\n",
    "final_model = XGBClassifier(\n",
    "    **best_params,\n",
    "    scale_pos_weight=spw,\n",
    "    objective=\"binary:logistic\",\n",
    "    eval_metric=\"auc\",\n",
    "    tree_method=\"hist\",\n",
    "    random_state=42,\n",
    "    n_jobs=-1,\n",
    "    early_stopping_rounds = 800,\n",
    ")\n",
    "\n",
    "\n",
    "# pequeno split so p early stopping\n",
    "X_tr, X_es, y_tr, y_es = train_test_split(\n",
    "    X_train_full,\n",
    "    y_train_full,\n",
    "    test_size=0.1,\n",
    "    stratify=y_train_full,\n",
    "    random_state=42\n",
    ")\n",
    "\n",
    "final_model.fit(\n",
    "    X_tr,\n",
    "    y_tr,\n",
    "    eval_set=[(X_es, y_es)],\n",
    "    verbose=200\n",
    ")\n",
    "\n",
    "# Save model\n",
    "os.makedirs(\"../models\", exist_ok=True)\n",
    "joblib.dump(final_model, \"../models/xgb_optuna_final.joblib\")\n",
    "final_model.save_model(\"../models/xgb_optuna_final.json\")\n",
    "\n",
    "print(\"Saved model artifacts:\")\n",
    "print(\" - ../models/xgb_optuna_final.joblib\")\n",
    "print(\" - ../models/xgb_optuna_final.json\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Results "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>model</th>\n",
       "      <th>roc_auc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HistGradientBoosting (stronger)</td>\n",
       "      <td>0.982588</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>XGBoost (improved v2)</td>\n",
       "      <td>0.979122</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>XGBoost (improved)</td>\n",
       "      <td>0.977621</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>XGBoost (improved v3)</td>\n",
       "      <td>0.977386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>XGBoost (baseline)</td>\n",
       "      <td>0.977386</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>XGBoost (improved)</td>\n",
       "      <td>0.976723</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>XGBoost (baseline)</td>\n",
       "      <td>0.976354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression (scaled baseline)</td>\n",
       "      <td>0.973616</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.951939</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HistGradientBoosting (tuned)</td>\n",
       "      <td>0.943165</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HistGradientBoosting</td>\n",
       "      <td>0.858295</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    model   roc_auc\n",
       "4         HistGradientBoosting (stronger)  0.982588\n",
       "8                   XGBoost (improved v2)  0.979122\n",
       "7                      XGBoost (improved)  0.977621\n",
       "9                   XGBoost (improved v3)  0.977386\n",
       "10                     XGBoost (baseline)  0.977386\n",
       "6                      XGBoost (improved)  0.976723\n",
       "5                      XGBoost (baseline)  0.976354\n",
       "0   Logistic Regression (scaled baseline)  0.973616\n",
       "1                           Random Forest  0.951939\n",
       "3            HistGradientBoosting (tuned)  0.943165\n",
       "2                    HistGradientBoosting  0.858295"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(results).sort_values(\"roc_auc\", ascending=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv (3.13.9)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
